# ================================================================
# File: ClusteringModel.py
# Má»¥c tiÃªu: PhÃ¢n cá»¥m khÃ¡ch hÃ ng dá»±a trÃªn dá»¯ liá»‡u RFM má»Ÿ rá»™ng
# ================================================================

import os
import warnings
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

warnings.filterwarnings("ignore")
os.environ["LOKY_MAX_CPU_COUNT"] = "4"

# ---------------------------------------------------------------
# 1. HÃ€M Xá»¬ LÃ Dá»® LIá»†U
# ---------------------------------------------------------------
def load_data(file_path: str) -> pd.DataFrame:
    """Äá»c dá»¯ liá»‡u Ä‘Ã£ tiá»n xá»­ lÃ½"""
    df = pd.read_csv(file_path)
    print(f"[INFO] ÄÃ£ load {len(df):,} khÃ¡ch hÃ ng.")
    return df


# ---------------------------------------------------------------
# 2. HÃ€M XÃC Äá»ŠNH Sá» Cá»¤M Tá»I Æ¯U (Elbow Method)
# ---------------------------------------------------------------
def find_optimal_clusters(X, max_k=10):
    """Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ Elbow Ä‘á»ƒ chá»n sá»‘ cá»¥m K tá»‘i Æ°u"""
    inertia = []
    for k in range(2, max_k + 1):
        model = KMeans(n_clusters=k, random_state=42, n_init=10)
        model.fit(X)
        inertia.append(model.inertia_)

    plt.figure(figsize=(6, 4))
    plt.plot(range(2, max_k + 1), inertia, marker='o')
    plt.xlabel("Sá»‘ cá»¥m (k)")
    plt.ylabel("Inertia")
    plt.title("Biá»ƒu Ä‘á»“ Elbow xÃ¡c Ä‘á»‹nh sá»‘ cá»¥m tá»‘i Æ°u")
    plt.tight_layout()
    plt.show()


# ---------------------------------------------------------------
# 3. HÃ€M PHÃ‚N Cá»¤M Báº°NG KMEANS
# ---------------------------------------------------------------
def run_kmeans(df: pd.DataFrame, features: list, k: int = 4) -> pd.DataFrame:
    """Huáº¥n luyá»‡n KMeans vÃ  thÃªm nhÃ£n cá»¥m vÃ o DataFrame"""
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(df[features])

    model = KMeans(n_clusters=k, random_state=42, n_init=10)
    df["Cluster"] = model.fit_predict(X_scaled)
    print(f"[âœ…] ÄÃ£ phÃ¢n cá»¥m thÃ nh {k} nhÃ³m khÃ¡ch hÃ ng.")
    return df


# ---------------------------------------------------------------
# 4. HÃ€M PHÃ‚N TÃCH CHI TIáº¾T CÃC Cá»¤M
# ---------------------------------------------------------------
def analyze_clusters(df: pd.DataFrame, features: list):
    """In ra thá»‘ng kÃª chi tiáº¿t tá»«ng cá»¥m khÃ¡ch hÃ ng"""
    summary = df.groupby("Cluster")[features].mean().round(2)
    counts = df["Cluster"].value_counts()

    print("\nğŸ“Š === Tá»”NG QUAN PHÃ‚N Cá»¤M ===")
    print(summary)
    print("\nSá»‘ lÆ°á»£ng khÃ¡ch hÃ ng trong tá»«ng cá»¥m:")
    print(counts)

    print("\nğŸ§© === PHÃ‚N TÃCH CHI TIáº¾T ===")
    for cluster_id in summary.index:
        data = summary.loc[cluster_id]
        size = counts[cluster_id]
        print(f"\n--- Cá»¥m {cluster_id} ({size} khÃ¡ch hÃ ng) ---")
        print(f"Recency TB: {data['Recency']}")
        print(f"Frequency TB: {data['Frequency']}")
        print(f"Monetary TB: {data['Monetary']}")
        print(f"TotalQuantity TB: {data['TotalQuantity']}")
        print(f"AvgUnitPrice TB: {data['AvgUnitPrice']}")

        # Diá»…n giáº£i gá»£i Ã½
        if data['Monetary'] > summary['Monetary'].mean() and data['Frequency'] > summary['Frequency'].mean():
            desc = "ğŸ”¥ KhÃ¡ch hÃ ng VIP / Trung thÃ nh - chi tiÃªu vÃ  táº§n suáº¥t mua cao."
        elif data['Recency'] < summary['Recency'].mean() and data['Frequency'] > summary['Frequency'].mean():
            desc = "ğŸ’ KhÃ¡ch hÃ ng tiá»m nÄƒng - mua gáº§n Ä‘Ã¢y vÃ  khÃ¡ thÆ°á»ng xuyÃªn."
        elif data['Recency'] > summary['Recency'].mean() and data['Frequency'] < summary['Frequency'].mean():
            desc = "âš ï¸ KhÃ¡ch hÃ ng khÃ´ng hoáº¡t Ä‘á»™ng - lÃ¢u chÆ°a quay láº¡i, táº§n suáº¥t tháº¥p."
        else:
            desc = "ğŸ“¦ NhÃ³m khÃ¡ch hÃ ng trung bÃ¬nh hoáº·c Ä‘áº·c biá»‡t (cÃ³ thá»ƒ lÃ  outlier)."

        print("â†’ Nháº­n xÃ©t:", desc)

    return summary


# ---------------------------------------------------------------
# 5. HÃ€M LÆ¯U Káº¾T QUáº¢
# ---------------------------------------------------------------
def save_clustered_data(df: pd.DataFrame, output_path: str):
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    df.to_csv(output_path, index=False)
    print(f"\n[ğŸ’¾] ÄÃ£ lÆ°u dá»¯ liá»‡u phÃ¢n cá»¥m táº¡i: {output_path}")


# ---------------------------------------------------------------
# 6. HÃ€M CHÃNH (CHáº Y TOÃ€N Bá»˜)
# ---------------------------------------------------------------
def main():
    input_path = "../data/datafinal.csv"
    output_path = "../data/rfm_clustered.csv"
    features = ["Recency", "Frequency", "Monetary", "TotalQuantity", "AvgUnitPrice"]

    df = load_data(input_path)
    # find_optimal_clusters(df[features])  # Báº­t náº¿u muá»‘n xem biá»ƒu Ä‘á»“ Elbow
    df_clustered = run_kmeans(df, features, k=4)
    analyze_clusters(df_clustered, features)
    save_clustered_data(df_clustered, output_path)


if __name__ == "__main__":
    main()
